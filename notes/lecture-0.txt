Lecture 0

- Search
    
    "We would like the AI to be able to search for solutions"
    
    Example: Driving directions (google mnaps)
    
    Terms:
        Agent: Entity that perceives its environment and acts upon that environment
        State: a configuration of the agent in its environment
        Initial State: the state where the agent begins
        Actions: choices that can be made in a state
            - as a function:
                Actions(s)
                    returns the set of actions that can be executed in state s 
        Transition Model: a description of what state results from performing any action in any state
            - as a function
                Result(s,a)
                    returns the state resulting from performing action a in state s
        State Space: the set of all states reachable from the initial state by any sequence of actions
        Goal Test: way to determine wheter a given state is a goal state
        Path Cost: numerical cost associated with a given path
        Solution: a sequence of actions that leads from the initial state to the goal state
        Optimal Solution: a solution that has the lowest path cost among all solutions
        node: a data structure that keeps track of 
            - a state
            - a parent (node that generated this node)
            - an action (action applied to parent to get node)
            - a path cost (from initial state to node)
        stack: last-in first-out data type
        queue: first-in first-out data type
        depth-first search (DFS): search algorithm that always expands the deepest node in the frontier
            - ex: goes down route until it hits dead end
        breadth-first search (BFS): search algorithm that always expands the shallowest node in the frontier
            - ex: looks at nodes that are 1 node away from initial state, then 2, then 3 etc.

    Search Problem:
        - initial state
        - actions
        - transition model
        - goal test
        - path cost function

    Approach Examples
        - start with a frontier that contains the initial state
        - repeat:
            - if frontier is empty, then no solution 
            - remove a node from the frontier
            - if node contains goal state, return the solution
            - expand node, add resulting nodes to the frontier
        - pitfall
            - can get caught in infinite loop of nodes have more than one direction
                - ex: A --> B but B can go B --> A, B --> C, B --> D
    
    Revised Approach
        - start with a frontier that contains the initial state
        - start with an empty explored set
        - repeat:
            - if frontier is empty, then no solution 
            - remove a node from the frontier
            - if node contains goal state, return the solution
            - add the node to the explored set
            - expand node, add resulting nodes to the frontier if they are not already in the frontier or the explored set
        This is called "Depth-First Search"